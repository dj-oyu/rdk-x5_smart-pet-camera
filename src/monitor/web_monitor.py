"""
Web„É¢„Éã„Çø„ÉºÂÆüË£Ö

Flask + MJPEG„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÅßBBoxÂêàÊàêÊò†ÂÉè„Çí„Éñ„É©„Ç¶„Ç∂„Å´Ë°®Á§∫
"""

from flask import Flask, Response, render_template_string
import cv2
import numpy as np
import json
from typing import Optional
import queue
import threading
import time
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent / "common" / "src"))
# ÂÖ±ÈÄöÂûãÂÆöÁæ©„Çí„Ç§„É≥„Éù„Éº„Éà
from common.types import Frame, DetectionResult, Detection, BoundingBox, DetectionClass

# MockSharedMemory„Çí„Ç§„É≥„Éù„Éº„ÉàÔºàÂûã„Éí„É≥„ÉàÁî®Ôºâ
sys.path.insert(0, str(Path(__file__).parent.parent / "mock"))
from shared_memory import MockSharedMemory


# Ëâ≤ÂÆöÁæ©ÔºàBGRÔºâ
COLORS = {
    "cat": (0, 255, 0),          # Á∑ë
    "food_bowl": (0, 165, 255),  # „Ç™„É¨„É≥„Ç∏
    "water_bowl": (255, 0, 0),   # Èùí
}


class WebMonitor:
    """
    Web„É¢„Éã„Çø„Éº

    ÂÖ±Êúâ„É°„É¢„É™„Åã„Çâ„Éï„É¨„Éº„É†„Å®Ê§úÂá∫ÁµêÊûú„ÇíË™≠„ÅøÂèñ„Çä„ÄÅ
    BBox„ÇíÂêàÊàê„Åó„Å¶„Éñ„É©„Ç¶„Ç∂„Å´MJPEG„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÈÖç‰ø°„Åô„Çã„ÄÇ

    Attributes:
        shm: ÂÖ±Êúâ„É°„É¢„É™
        fps: ÁõÆÊ®ô„Éï„É¨„Éº„É†„É¨„Éº„Éà
        jpeg_quality: JPEGÂìÅË≥™Ôºà1-100Ôºâ
        frame_queue: „Éï„É¨„Éº„É†„Ç≠„É•„Éº
    """

    def __init__(
        self,
        shm: MockSharedMemory,
        fps: int = 30,
        jpeg_quality: int = 80,
    ) -> None:
        """
        ÂàùÊúüÂåñ

        Args:
            shm: ÂÖ±Êúâ„É°„É¢„É™
            fps: ÁõÆÊ®ô„Éï„É¨„Éº„É†„É¨„Éº„Éà
            jpeg_quality: JPEGÂìÅË≥™Ôºà1-100Ôºâ
        """
        self.shm = shm
        self.fps = fps
        self.jpeg_quality = jpeg_quality
        self.frame_interval = 1.0 / fps

        # „Éï„É¨„Éº„É†„Ç≠„É•„ÉºÔºàÊúÄÊñ∞2„Éï„É¨„Éº„É†„ÅÆ„Åø‰øùÊåÅÔºâ
        self.frame_queue: queue.Queue[bytes] = queue.Queue(maxsize=2)

        # Áµ±Ë®àÊÉÖÂ†±
        self.stats = {
            "frames_processed": 0,
            "current_fps": 0.0,
            "detection_count": 0,
        }

        # Overlay„Çπ„É¨„ÉÉ„ÉâÂà∂Âæ°
        self._running = False
        self._overlay_thread: Optional[threading.Thread] = None

    def start(self) -> None:
        """Overlay„Çπ„É¨„ÉÉ„Éâ„ÇíÈñãÂßã"""
        if self._running:
            return

        self._running = True
        self._overlay_thread = threading.Thread(target=self._overlay_loop, daemon=True)
        self._overlay_thread.start()
        print("WebMonitor: Overlay thread started")

    def stop(self) -> None:
        """Overlay„Çπ„É¨„ÉÉ„Éâ„ÇíÂÅúÊ≠¢"""
        self._running = False
        if self._overlay_thread:
            self._overlay_thread.join(timeout=2.0)
        print("WebMonitor: Overlay thread stopped")

    def _overlay_loop(self) -> None:
        """Overlay„É´„Éº„ÉóÔºà30fpsÔºâ"""
        cached_detections: Optional[DetectionResult] = None
        cached_version = 0
        last_time = time.time()
        frame_count = 0

        while self._running:
            start_time = time.time()

            # „Éï„É¨„Éº„É†ÂèñÂæó
            frame = self.shm.read_latest_frame()
            if frame is None:
                time.sleep(0.01)
                continue

            # Ê§úÂá∫ÁµêÊûúÂèñÂæóÔºàÊõ¥Êñ∞„Åï„Çå„Å¶„ÅÑ„Çå„Å∞Ôºâ
            current_version = self.shm.get_detection_version()
            if current_version != cached_version:
                detection_result, cached_version = self.shm.read_detection()
                parsed = self._parse_detection_result(detection_result)
                if parsed:
                    cached_detections = parsed

            # BBoxÂêàÊàê
            overlay_frame = self._draw_overlay(frame, cached_detections)

            # JPEG„Ç®„É≥„Ç≥„Éº„Éâ
            _, encoded = cv2.imencode(
                '.jpg',
                overlay_frame,
                [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality]
            )
            jpeg_data = encoded.tobytes()

            # „Ç≠„É•„Éº„Å´ËøΩÂä†ÔºàÂè§„ÅÑ„Éï„É¨„Éº„É†„ÅØÊç®„Å¶„ÇãÔºâ
            try:
                self.frame_queue.put_nowait(jpeg_data)
            except queue.Full:
                try:
                    self.frame_queue.get_nowait()
                    self.frame_queue.put_nowait(jpeg_data)
                except queue.Empty:
                    pass

            # Áµ±Ë®àÊõ¥Êñ∞
            frame_count += 1
            self.stats["frames_processed"] += 1
            if time.time() - last_time >= 1.0:
                self.stats["current_fps"] = frame_count / (time.time() - last_time)
                frame_count = 0
                last_time = time.time()

            # „Éï„É¨„Éº„É†„É¨„Éº„ÉàÂà∂Âæ°
            elapsed = time.time() - start_time
            if elapsed < self.frame_interval:
                time.sleep(self.frame_interval - elapsed)

    def _parse_detection_result(
        self, detection_result_raw: Optional[object]
    ) -> Optional[DetectionResult]:
        """
        Ê§úÂá∫ÁµêÊûú„Çí„Éá„Ç∑„É™„Ç¢„É©„Ç§„Ç∫„Åó„ÄÅDetectionResult„Å´Â§âÊèõ„Åô„Çã„ÄÇ

        ÂÖ±Êúâ„É°„É¢„É™„Åã„ÇâJSONÊñáÂ≠óÂàó/ËæûÊõ∏„ÅßÊ∏°„Åï„Çå„Åü„Ç±„Éº„Çπ„Å´„ÇÇÂØæÂøú„Åô„Çã„ÄÇ
        """
        if detection_result_raw is None:
            return None

        if isinstance(detection_result_raw, DetectionResult):
            return detection_result_raw

        try:
            if isinstance(detection_result_raw, (str, bytes, bytearray)):
                detection_dict = json.loads(detection_result_raw)
            elif isinstance(detection_result_raw, dict):
                detection_dict = detection_result_raw
            else:
                print(f"[WARN] Unsupported detection result type: {type(detection_result_raw)}")
                return None

            detections = []
            for det in detection_dict.get("detections", []):
                bbox_data = det.get("bbox", {})
                bbox = BoundingBox(
                    x=int(bbox_data.get("x", 0)),
                    y=int(bbox_data.get("y", 0)),
                    w=int(bbox_data.get("w", 0)),
                    h=int(bbox_data.get("h", 0)),
                )
                try:
                    class_enum = DetectionClass(det.get("class_name"))
                except ValueError:
                    # class_name„ÅåÊú™ÂÆöÁæ©„Å™„Çâ„Çπ„Ç≠„ÉÉ„Éó
                    continue
                detections.append(
                    Detection(
                        class_name=class_enum,
                        confidence=float(det.get("confidence", 0.0)),
                        bbox=bbox,
                    )
                )

            return DetectionResult(
                frame_number=int(detection_dict.get("frame_number", 0)),
                timestamp=float(detection_dict.get("timestamp", time.time())),
                detections=detections,
                version=int(detection_dict.get("version", 0)),
            )
        except Exception as exc:
            print(f"[WARN] Failed to parse detection result: {exc}")
            return None

    def _draw_overlay(
        self,
        frame: Frame,
        detection_result: Optional[DetectionResult]
    ) -> np.ndarray:
        """
        BBox„ÇíÂêàÊàê

        Args:
            frame: ÂÖ•Âäõ„Éï„É¨„Éº„É†
            detection_result: Ê§úÂá∫ÁµêÊûú

        Returns:
            BBoxÂêàÊàêÊ∏à„Åø„ÅÆ„Éï„É¨„Éº„É†ÔºàBGRÔºâ
        """
        # JPEG „Éá„Ç≥„Éº„Éâ
        np_arr = np.frombuffer(frame.data, np.uint8)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        if detection_result is None or not detection_result.detections:
            # Ê§úÂá∫ÁµêÊûú„Å™„Åó
            self._draw_info_text(img, frame, None)
            return img

        # BBox„ÇíÊèèÁîª
        for detection in detection_result.detections:
            self._draw_detection(img, detection)

        # ÊÉÖÂ†±„ÉÜ„Ç≠„Çπ„Éà„ÇíÊèèÁîª
        self._draw_info_text(img, frame, detection_result)

        self.stats["detection_count"] = detection_result.num_detections

        return img

    def _draw_detection(self, img: np.ndarray, detection: Detection) -> None:
        """Ê§úÂá∫ÁµêÊûú„ÇíÊèèÁîª"""
        bbox = detection.bbox
        class_name = detection.class_name.value
        confidence = detection.confidence

        # Ëâ≤„ÇíÂèñÂæó
        color = COLORS.get(class_name, (255, 255, 255))

        # „Éê„Ç¶„É≥„Éá„Ç£„É≥„Ç∞„Éú„ÉÉ„ÇØ„Çπ„ÇíÊèèÁîª
        cv2.rectangle(
            img,
            (bbox.x, bbox.y),
            (bbox.x + bbox.w, bbox.y + bbox.h),
            color,
            2
        )

        # „É©„Éô„É´„ÇíÊèèÁîª
        label = f"{class_name}: {confidence:.2f}"
        label_size, baseline = cv2.getTextSize(
            label,
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            1
        )
        label_y = max(bbox.y - 10, label_size[1] + 10)

        # „É©„Éô„É´ËÉåÊôØ
        cv2.rectangle(
            img,
            (bbox.x, label_y - label_size[1] - baseline),
            (bbox.x + label_size[0], label_y + baseline),
            color,
            -1
        )

        # „É©„Éô„É´„ÉÜ„Ç≠„Çπ„Éà
        cv2.putText(
            img,
            label,
            (bbox.x, label_y),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 0, 0),
            1
        )

    def _draw_info_text(
        self,
        img: np.ndarray,
        frame: Frame,
        detection_result: Optional[DetectionResult]
    ) -> None:
        """ÊÉÖÂ†±„ÉÜ„Ç≠„Çπ„Éà„ÇíÊèèÁîª"""
        info_lines = [
            f"Frame: #{frame.frame_number}",
            f"FPS: {self.stats['current_fps']:.1f}",
            f"Camera: {frame.camera_id}",
        ]

        if detection_result:
            info_lines.append(f"Detections: {detection_result.num_detections}")

        y_offset = 30
        for line in info_lines:
            cv2.putText(
                img,
                line,
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 255),
                2
            )
            y_offset += 25

    def generate_mjpeg(self):
        """MJPEG„Çπ„Éà„É™„Éº„É†„ÇíÁîüÊàêÔºàFlaskÁî®„Ç∏„Çß„Éç„É¨„Éº„ÇøÔºâ"""
        while True:
            try:
                frame = self.frame_queue.get(timeout=1.0)
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
            except queue.Empty:
                continue


def create_app(shm: MockSharedMemory, monitor: WebMonitor) -> Flask:
    """Flask„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰ΩúÊàê"""
    app = Flask(__name__)

    @app.route('/')
    def index():
        """„É°„Ç§„É≥„Éö„Éº„Ç∏"""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>Smart Pet Camera Monitor</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    background: #1a1a1a;
                    color: #fff;
                    margin: 0;
                    padding: 20px;
                }
                #container {
                    max-width: 1400px;
                    margin: 0 auto;
                }
                h1 {
                    text-align: center;
                    margin-bottom: 20px;
                }
                #video-panel {
                    position: relative;
                    background: #000;
                    border: 2px solid #444;
                    border-radius: 8px;
                    overflow: hidden;
                }
                #stream {
                    width: 100%;
                    display: block;
                }
                #stats-panel {
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                    margin-top: 20px;
                }
                .stat-card {
                    background: #2a2a2a;
                    padding: 15px;
                    border-radius: 8px;
                    border: 1px solid #444;
                }
                .stat-card h3 {
                    margin: 0 0 10px 0;
                    font-size: 14px;
                    color: #888;
                }
                .stat-value {
                    font-size: 24px;
                    font-weight: bold;
                    color: #4CAF50;
                }
            </style>
        </head>
        <body>
            <div id="container">
                <h1>üê± Smart Pet Camera Monitor</h1>

                <div id="video-panel">
                    <img id="stream" src="/stream">
                </div>

                <div id="stats-panel">
                    <div class="stat-card">
                        <h3>Camera FPS</h3>
                        <div class="stat-value" id="fps">--</div>
                    </div>
                    <div class="stat-card">
                        <h3>Frames Processed</h3>
                        <div class="stat-value" id="frames">--</div>
                    </div>
                    <div class="stat-card">
                        <h3>Detections</h3>
                        <div class="stat-value" id="detections">--</div>
                    </div>
                </div>
            </div>

            <script>
                // Áµ±Ë®àÊÉÖÂ†±„ÇíÂÆöÊúüÁöÑ„Å´Êõ¥Êñ∞ÔºàÂ∞ÜÊù•ÁöÑ„Å´WebSocket/SSE„ÅßÂÆüË£ÖÔºâ
                setInterval(() => {
                    // TODO: „Çµ„Éº„Éê„Éº„Åã„ÇâÁµ±Ë®àÊÉÖÂ†±„ÇíÂèñÂæó
                }, 1000);
            </script>
        </body>
        </html>
        """
        return render_template_string(html)

    @app.route('/stream')
    def video_stream():
        """MJPEG„Çπ„Éà„É™„Éº„É†"""
        return Response(
            monitor.generate_mjpeg(),
            mimetype='multipart/x-mixed-replace; boundary=frame'
        )

    return app


# ‰ΩøÁî®‰æãÔºàÂæå„Åßmain.py„Åã„ÇâÂëº„Å≥Âá∫„ÅôÔºâ
if __name__ == "__main__":
    print("WebMonitor cannot run standalone. Use main.py to start the system.")
